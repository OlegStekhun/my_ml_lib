# üì¶ my-ml-lib

> –õ—ë–≥–∫–∞—è –∏ —É–¥–æ–±–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ —Å—Ç–∏–ª–µ [scikit-learn](https://scikit-learn.org/).  
> –°–æ–¥–µ—Ä–∂–∏—Ç –±–∞–∑–æ–≤—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞.  

![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-beta-orange.svg)

---

## ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üß© **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**:  
  Logistic Regression, KNN, Decision Tree, Random Forest, Gradient Boosting, SVM  

- üìà **–†–µ–≥—Ä–µ—Å—Å–∏—è**:  
  Linear Regression, KNN, Decision Tree, Random Forest, Gradient Boosting  

- üîç **–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è**:  
  KMeans, Agglomerative, DBSCAN  

- üî¨ **–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏**:  
  PCA  

- üìä **–ú–µ—Ç—Ä–∏–∫–∏**:  
  - –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: Accuracy, Precision, Recall, F1, ROC AUC  
  - –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: MAE, MSE, RMSE, MAPE, R¬≤  
  - –î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: Silhouette, Calinski-Harabasz, Davies-Bouldin  

---

## üìö –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

–î–ª—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–≥—Ä—É–∂–µ–Ω–∏—è –≤ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, –∑–∞–≥–ª—è–Ω–∏—Ç–µ –≤ –ø–∞–ø–∫—É `examples/`. –¢–∞–º –≤—ã –Ω–∞–π–¥–µ—Ç–µ Jupyter-–Ω–æ—É—Ç–±—É–∫–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –ø–æ:
* –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (`Classification_example.ipynb`)
* –†–µ–≥—Ä–µ—Å—Å–∏–∏ (`Regression_example.ipynb`)
* –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (`Clasterisation_example.ipynb`)

–í —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö —Ç–∞–∫–∂–µ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è **—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Å –∏—Ö –∞–Ω–∞–ª–æ–≥–∞–º–∏ –∏–∑ `scikit-learn`**.

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
pip install my-ml-lib



